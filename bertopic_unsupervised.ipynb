{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc9ec7-5aa8-433c-9712-10ef101007f8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install bertopic[flair,gensim,spacy,use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdcade-f0d0-4db8-a5a4-035d90fde762",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic[vision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299107e-5af2-4195-a8b0-0efc6084ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import openai\n",
    "from bertopic.representation import OpenAI\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9eeaf-9f0f-40ac-8538-899e6a9364ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b401921-e817-4ba3-9fc4-7bc9cb67d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text_without_punctuation = text.translate(translator)\n",
    "    return text_without_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558f965-d51b-4b4f-a25e-372fcf724cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    stop_words.update([\"nº\",\"cep\",\"telefone\",\"rua\",\"avenida\",\"endereço\",\"fax\",\"fones\"])\n",
    "    stop_words.update([\"egrégia\",\"egrégio\",\"eg\",\"e.g.\"])\n",
    "    stop_words.update([\"copy\",\"reg\",\"trade\",\"ldquo\",\"rdquo\",\"lsquo\",\"rsquo\",\"bull\",\"middot\",\"sdot\",\"ndash\",\"mdash\",\"cent\",\"pound\",\"euro\",\"ne\",\"frac12\",\"frac14\",\"frac34\",\"deg\",\"larr\",\"rarr\",\"uarr\",\"darr\",\"egrave\",\"eacute\",\"ccedil\",\"hellip\"])\n",
    "    tokens = nltk.word_tokenize(text, language='portuguese')\n",
    "    tokens_cleaned = [token for token in tokens if token not in stop_words]\n",
    "    text_cleaned = ' '.join(tokens_cleaned)\n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1f6f2-9420-43a7-a871-d371f05ef609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(doc):\n",
    "    final_doc = \"\"\n",
    "    doc = doc.lower()\n",
    "    #Tenta identificar parte relevante do documento\n",
    "    match = re.search(r' cabimento[^\\n]*',doc)\n",
    "    #Palavras irrelevantes\n",
    "    match_pattern = [r'\\b_+(?:\\d+|[a-zA-Z]+)?\\b',r'https?://\\S+',r'www\\.\\S+',r'\\S+@\\S+',r'^\\d{3}.\\d{3}.\\d{3}-\\d{2}$',r'^\\d{2}\\.\\d{3}\\.\\d{3}\\/\\d{4}\\-\\d{2}$',r'\\d{2}/\\d{2}/\\d{4}[ ,]',r'procuradoria regional (federal|da união) da \\d+[ªa] região',r'tribunal regional federal[ da] \\d+[ªa] região',r'advocacia[ -]geral da união',r'(excelentíssimo|senhor|vice-presidente|desembargador|\\(a\\))',r'procuradoria[ -]geral federal',r'escritório de advocacia',r'[ superior] tribunal de justiça',r'supremo tribunal federal',r'fones',r'fax']\n",
    "    subs = [''] * len(match_pattern)\n",
    "    if match:\n",
    "        start = match.start()\n",
    "        final_doc = doc[start:]\n",
    "    else:\n",
    "        final_doc = doc\n",
    "    for match_pattern, subs in zip(match_pattern,subs):\n",
    "        final_doc = re.sub(match_pattern,subs,final_doc)\n",
    "    final_doc = remove_stopwords(final_doc)\n",
    "        \n",
    "    return final_doc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e61516-109a-4dbe-9d12-e9ce86a0b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_tfidf(text,stop_words):\n",
    "    tokens = nltk.word_tokenize(text, language='portuguese')\n",
    "    tokens_cleaned = [token for token in tokens if token not in stop_words]\n",
    "    text_cleaned = ' '.join(tokens_cleaned)\n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4adfb-33a4-403c-a669-16afdc582699",
   "metadata": {
    "id": "ho2P0r4xD0MC"
   },
   "source": [
    "## **Lê recursos a partir do dataset e faz limpeza inicial dos textos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42559cf5-68b3-4240-8d85-f641afbecbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lê recursos especiais\n",
    "resp = pd.read_csv('REsp_completo.csv')\n",
    "\n",
    "docs = []\n",
    "num_cadastrado = []\n",
    "indice = []\n",
    "clean = True\n",
    "\n",
    "for i, linha in resp.iterrows():\n",
    "  tipo = type(linha['recurso'])\n",
    "  try:\n",
    "    #tratamento necessário, textos estavam sendo identificados como float\n",
    "    if (tipo == str):\n",
    "      if clean:\n",
    "          doc_cleaned = clean_text(linha['recurso'])\n",
    "          num_cadastrado.append(int(linha['num_tema_cadastrado']))\n",
    "          docs.append(doc_cleaned)\n",
    "          indice.append(i)     \n",
    "      else:\n",
    "          num_cadastrado.append(int(linha['num_tema_cadastrado']))\n",
    "          docs.append(linha['recurso'])\n",
    "          indice.append(i)\n",
    "      \n",
    "  except Exception as erro:\n",
    "    print(f\"Erro ao capturar numero de tema cadastrado {i}\")\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f4742-9cea-4105-ac2d-e8ff9fe17b29",
   "metadata": {
    "id": "ho2P0r4xD0MC"
   },
   "source": [
    "## **Cria matriz tf-idf e a partir de um limite estabelecido, cria um conjunto de stopwords e faz nova limpeza dos textos antes de inicar a modelagem de topicos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67041e64-38e0-4b8a-8571-23d065e63f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vocab)\n",
    "\n",
    "# limite para o valor de TF-IDF\n",
    "limite_tfidf = 0.006\n",
    "\n",
    "# Encontra as palavras com TF-IDF inferior ao limite em todos os registros\n",
    "inferior_tfidf_words_all = df_tfidf.columns[df_tfidf.lt(limite_tfidf).all()]\n",
    "\n",
    "stopwords_list = inferior_tfidf_words_all.tolist()\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    docs[i]=remove_stopwords_tfidf(docs[i],stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f92cf3-c66d-4cfb-9543-660c55b67749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa8c3a-c553-4eb1-93e3-7d8e49c0009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce903b-2b56-4ea2-8c06-223cc69fcb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria lista de temas apartir de arquivo\n",
    "temas_repetitivos_eproc = pd.read_csv('temas_repetitivos.csv', sep=',' )\n",
    "temas = temas_repetitivos_eproc[['tema','num_tema_cadastrado']].copy()\n",
    "temas.columns = ['texto','numTema']\n",
    "list_temas = list(temas.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be454dce-fe91-4e1b-bd7c-da8f42494b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "temas_seed_list = []\n",
    "temas_seed = temas_repetitivos_eproc[['tema']].copy()\n",
    "temas_seed.columns = ['texto']\n",
    "for indice,linha in temas_seed.iterrows():\n",
    "    seed = clean_text(linha[0])\n",
    "    seed = remove_punctuation(seed)\n",
    "    temas_seed_list.append(seed.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02bee6-a97d-437f-ad9e-bbab31565d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(temas_seed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a2e3a-b683-4cf0-9ed5-f6320b2c2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(docs)\n",
    "#print(docs[470])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f0a64-dfcd-49dd-b666-e0f3f4f32faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_cadastrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c461af8-886c-4a00-8396-595885041764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega modelo pré-treinado pra criar embeddings dos textos \n",
    "#Modelo do bertopic não estava gerando corretamente topicos em portugues estava excluindo letras acentuadas e cedilha\n",
    "sentence_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "topic_model = BERTopic(embedding_model=sentence_model,top_n_words=13, seed_topic_list=temas_seed_list)\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0279a3d-9f25-494c-9605-95c81d0498fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info=topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80acfb98-b135-449b-ac70-a6cff200a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "representacao = topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ace44-8f95-46db-b9fd-312afecaddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(representacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fd974-11c7-4e07-84ef-bbb5f0c9b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = topic_model.vectorizer_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123d62b-9ef0-46b5-bf7b-208c20653a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd6ffd-0ac7-4df4-a88b-9e6e8ffd545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_term_rank(log_scale=True)\n",
    "fig.write_html(\"grafico_topicos.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671f6c3-229e-44e4-9db5-6ab141df592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_unsupervised = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e346e-5582-4586-a949-5c3f5068265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_unsupervised[\"indice\"]=indice\n",
    "bertopic_unsupervised[\"num_tema_cadastrado\"]=num_cadastrado\n",
    "bertopic_unsupervised[\"recurso\"]=docs\n",
    "bertopic_unsupervised[\"topicos\"]=representacao['Top_n_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994b40e-1ca5-4ed2-8898-1ca3ae78e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bertopic_unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced8dee-e148-488a-a955-ae962d99eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salva em arquivo os textos com topicos principais extraidos e numeros de temas reais cadastrados\n",
    "file = 'bertopic_nao_supervisionado.csv'\n",
    "bertopic_unsupervised.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01312469-77e0-43d7-96a6-b680a7383338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(dataframe, linha, coluna):\n",
    "    texto = dataframe.at[linha, coluna]\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b2566-97ac-4140-9a1f-c07fd4d3d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_list(lista):\n",
    "    return(sorted(lista, key = lambda x: x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4e631-a9b4-4004-9f3a-e819fc9373ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_similarity(topics, temas ,k,tema_real):\n",
    "  lista_similaridade = []\n",
    "  lista_tema_real = []\n",
    "  \n",
    "  for indice, tupla_num_tema in enumerate(temas):\n",
    "      query_embedding = sentence_model.encode(topics)\n",
    "      #print(f\"Tema {indice} : {tupla_num_tema[0]}\")\n",
    "      tema_cleaned = clean_text(tupla_num_tema[0])\n",
    "      text_embedding = sentence_model.encode(tema_cleaned)\n",
    "      tensor_similaridade = util.cos_sim(query_embedding, text_embedding)\n",
    "      valor_similaridade = tensor_similaridade.item()\n",
    "      tupla = (tupla_num_tema[1],valor_similaridade)\n",
    "      lista_similaridade.append(tupla)\n",
    "\n",
    "  sorted_list = sort_list(lista_similaridade)\n",
    "  for i, linha in enumerate(sorted_list):\n",
    "      if(linha[0]==tema_real):\n",
    "        lista_tema_real.append(i+1)#identifica posição do tema real no ranking\n",
    "        lista_tema_real.append(linha[1]) \n",
    "        break\n",
    "  ranking = sorted_list[:k]\n",
    "  return ranking,lista_tema_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631785f2-41ec-4169-9c0d-fb3364f77a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns(k):\n",
    "  #k refere-se ao numero de elementos no ranking\n",
    "  colunas = []\n",
    "  colunas.append(\"indice\")\n",
    "  colunas.append(\"num_tema_cadastrado\")\n",
    "  for i in range(1, k + 1):\n",
    "    nome = f\"sugerido_{i}\"\n",
    "    colunas.append(nome)\n",
    "    nome = f\"similaridade_{i}\"\n",
    "    colunas.append(nome)\n",
    "  colunas.append(\"posicao_tema_real\")\n",
    "  colunas.append(\"similaridade_tema_real\")\n",
    "  return colunas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bdfb54-0b68-4fe5-a37e-c623956b7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria dataframe pra armazenar dados sobre textos classificados\n",
    "nomes_colunas = create_columns(6)\n",
    "resp_classificados = pd.DataFrame(columns=nomes_colunas)\n",
    "#Cria arquivo pra armazenar resultados\n",
    "#resp_classificados.to_csv('resp_classif_bertopic_unsuperv.csv', index=False)\n",
    "resp_classificados.to_csv('resp_bertopic_unsuperv_filter.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25696541-8b19-4424-87e8-d43f348bf1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#passa topicos de cada documento e lista de temas\n",
    "for indice, linha in bertopic_unsupervised.iterrows():\n",
    "  dados = []\n",
    "  dados.append(indice)\n",
    "  #numero do tema cadastrado por um analista\n",
    "  try:\n",
    "      dados.append(int(linha['num_tema_cadastrado']))\n",
    "  except Exception as erro:\n",
    "      print(f\"Erro ao capturar numero de tema cadastrado {indice}\")\n",
    "      continue\n",
    "  \n",
    "  try:\n",
    "    #retira hifen entre as palavras dos topicos\n",
    "      topicos = linha['topicos'].replace(\"-\",\"\")    \n",
    "      ranking , lista_tema_real = calc_similarity(topicos, list_temas, 6, linha['num_tema_cadastrado'])\n",
    "  except Exception as erro:\n",
    "      print(f\"Erro calculo similaridade indice {indice}\") \n",
    "      continue\n",
    "  for i, tupla_num_tema in enumerate(ranking):\n",
    "    #captura numero do tema sugerido e valor da similaridade\n",
    "    dados.append(tupla_num_tema[0])\n",
    "    dados.append(tupla_num_tema[1])\n",
    "  \n",
    "  if(lista_tema_real):\n",
    "    dados.append(lista_tema_real[0])\n",
    "    dados.append(lista_tema_real[1])\n",
    "  else:\n",
    "    dados.append(\"NA\")\n",
    "    dados.append(\"NA\")\n",
    "  #with open('resp_classif_bertopic_unsuperv.csv', mode='a', newline='') as arquivo:\n",
    "  with open('resp_bertopic_unsuperv_filter.csv', mode='a', newline='') as arquivo:\n",
    "    writer = csv.writer(arquivo)\n",
    "    writer.writerow(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0f2d5-00c4-413e-bd06-81ca7d4fe7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salva modelo\n",
    "topic_model.save(\"is_notes/my_model_bertopic.pt\", serialization=\"pytorch\", save_ctfidf=True, save_embedding_model=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4486d-ef05-4964-8eda-dcd1926f1840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
